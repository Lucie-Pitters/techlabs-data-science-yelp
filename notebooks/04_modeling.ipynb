{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modeling \n",
    "This notebook contains our machine learning algorithm (Naive Bayes: partially implemented, logistic regression: not implemented yet, ...). It builds on the preprocessing steps (bag-of-words and tf-idf). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, GridSearchCV\n",
    "from sklearn.naive_bayes import ComplementNB, MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, ENGLISH_STOP_WORDS\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from scipy.sparse import hstack\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TF-IDF scores\n",
    "tfidf_path = \"data/intermediate/tfidf_scores.csv\"\n",
    "tfidf_df = pd.read_csv(tfidf_path)\n",
    "\n",
    "# Generate labels heuristically (Example: Sentiment Lexicon or Clustering)\n",
    "# Placeholder: Random binary labels for now\n",
    "y = np.random.choice([0, 1], size=len(tfidf_df))\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    tfidf_df, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Train Naive Bayes classifier\n",
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = nb_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Cross-validation\n",
    "cv_scores = cross_val_score(nb_classifier, tfidf_df, y, cv=5)\n",
    "print(f\"Cross-validation accuracy: {cv_scores.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "# Initialize Lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Function for Text Preprocessing (Lemmatization & Cleaning)\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)  # Remove punctuation and special characters\n",
    "    tokens = word_tokenize(text)  # Tokenization\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(word) for word in tokens]  # Apply lemmatization\n",
    "    return \" \".join(lemmatized_tokens)  # Join back into a string\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_json(\"data/raw/reviews_2010.json\", lines=True)\n",
    "\n",
    "# Apply preprocessing to text column\n",
    "df['text'] = df['text'].apply(preprocess_text)\n",
    "\n",
    "# Define Multi-Class Sentiment Labels\n",
    "df['sentiment'] = df['stars'].apply(lambda x: 0 if x <= 2 else (1 if x == 3 else (2 if x == 4 else 3)))\n",
    "\n",
    "# Enhanced TF-IDF representation with expanded stopwords\n",
    "custom_stopwords = list(set(ENGLISH_STOP_WORDS).union({\"great\", \"good\", \"bad\", \"nice\", \"product\", \"service\"}))\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=150000,  \n",
    "    sublinear_tf=True,\n",
    "    max_df=0.7,  \n",
    "    min_df=3,  \n",
    "    ngram_range=(1, 2),  \n",
    "    stop_words=custom_stopwords,  \n",
    "    norm='l2'\n",
    ")\n",
    "X_tfidf = vectorizer.fit_transform(df['text'])\n",
    "\n",
    "# Feature Selection (Optional - Can Be Disabled)\n",
    "USE_CHI2_SELECTION = False  # Set to True if you want to enable feature selection\n",
    "\n",
    "if USE_CHI2_SELECTION:\n",
    "    chi2_selector = SelectKBest(chi2, k=min(25000, X_tfidf.shape[1]))  \n",
    "    X_tfidf = chi2_selector.fit_transform(X_tfidf, df['sentiment'])\n",
    "\n",
    "# Feature Engineering - Optimized Selection\n",
    "df['review_length'] = df['text'].apply(lambda x: len(x.split()))\n",
    "df['num_exclamation'] = df['text'].apply(lambda x: x.count('!'))\n",
    "df['avg_word_length'] = df['text'].apply(lambda x: np.mean([len(word) for word in x.split()]) if x.split() else 0)\n",
    "\n",
    "# Convert additional features to a numpy array\n",
    "X_additional = np.array(df[['review_length', 'num_exclamation', 'avg_word_length']])\n",
    "\n",
    "# Combine TF-IDF with additional features\n",
    "X_final = hstack((X_tfidf, X_additional))  \n",
    "y = df['sentiment'].values  \n",
    "\n",
    "# Split Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_final, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Optimize Naive Bayes Model with Expanded Hyperparameter Tuning\n",
    "param_grid = {'alpha': np.linspace(0.001, 2.0, 20)}  # Expanded range for better tuning\n",
    "grid_search = GridSearchCV(ComplementNB(), param_grid, cv=10, scoring='accuracy', n_jobs=-1)  \n",
    "grid_search.fit(X_train, y_train)\n",
    "best_alpha = grid_search.best_params_['alpha']\n",
    "\n",
    "# Train Optimized Naive Bayes Model\n",
    "nb_classifier = ComplementNB(alpha=best_alpha)\n",
    "nb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make Predictions\n",
    "y_pred = nb_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate Performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"âœ…  Accuracy: {accuracy:.4f}\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Negative', 'Neutral', 'Positive', 'Very Positive']))\n",
    "\n",
    "# Perform Stratified Cross-Validation\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "cv_scores = cross_val_score(nb_classifier, X_final, y, cv=skf, n_jobs=-1)\n",
    "print(f\" Stratified Cross-validation accuracy: {cv_scores.mean():.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
