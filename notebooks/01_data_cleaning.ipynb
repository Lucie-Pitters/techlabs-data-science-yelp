{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Cleaning \n",
    "This notebook cleans the review data by putting it to lowercase, removing special characters and numbers, removing duplicates and incomplete reviews. The file is then saved to data/intermediate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# --- Project Directory Setup ---\n",
    "# Get the parent directory (project root)\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "from src1 import load_json_lines, clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- File Paths Setup ---\n",
    "# Base directory (go 2 levels up from /src1/)\n",
    "base_dir = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "\n",
    "# Define input/output directories using relative paths\n",
    "input_dir = os.path.join(base_dir, \"data\", \"raw\")\n",
    "output_dir = os.path.join(base_dir, \"data\", \"intermediate\")\n",
    "\n",
    "input_filename = \"reviews_2021-01.json\"\n",
    "input_file = os.path.join(input_dir, input_filename)\n",
    "\n",
    "cleaned_file = os.path.join(output_dir, f\"cleaned_{input_filename}\")\n",
    "na_file = os.path.join(output_dir, \"NAs.json\")\n",
    "duplicates_file = os.path.join(output_dir, \"Duplicates.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Check if input file exists ---\n",
    "if not os.path.exists(input_file):\n",
    "    raise FileNotFoundError(f\"Error: File '{input_file}' not found.\")\n",
    "\n",
    "# --- Load Data ---\n",
    "reviews = load_json_lines(input_file)\n",
    "df = pd.DataFrame(reviews)\n",
    "\n",
    "# --- DataFrame creation ---\n",
    "df = pd.DataFrame(reviews)\n",
    "\n",
    "# --- Initial Checks ---\n",
    "print(f\"Initial data shape: {df.shape}\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")\n",
    "print(f\"Missing values per column:\\n{df.isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Text Cleaning ---\n",
    "if \"text\" in df.columns:\n",
    "    df[\"text\"] = df[\"text\"].apply(clean_text)  # Clean the text field\n",
    "    df[\"text\"] = (\n",
    "        df[\"text\"].str.replace(r\"\\s+\", \" \", regex=True).str.strip()\n",
    "    )  # Normalize whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Remove Duplicates ---\n",
    "duplicates = df[df.duplicated(subset=[\"review_id\"], keep=False)]\n",
    "if not duplicates.empty:\n",
    "    print(\n",
    "        f\"Found {duplicates.shape[0]} duplicate reviews. Saving to '{duplicates_file}'.\"\n",
    "    )\n",
    "    duplicates.to_json(duplicates_file, orient=\"records\", lines=True, force_ascii=False)\n",
    "\n",
    "df = df.drop_duplicates(subset=[\"review_id\"], keep=\"first\")  # Remove duplicate reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Remove Empty Reviews ---\n",
    "df = df[df[\"text\"].str.len() > 0]  # Remove reviews with empty text\n",
    "\n",
    "# --- Handle Missing Values ---\n",
    "nas = df[df.isnull().any(axis=1)]\n",
    "if not nas.empty:\n",
    "    print(f\"Found {nas.shape[0]} rows with missing values. Saving them to '{na_file}'.\")\n",
    "    nas.to_json(na_file, orient=\"records\", lines=True, force_ascii=False)\n",
    "\n",
    "df = df.dropna()  # Drop rows with any missing values\n",
    "print(f\"Data shape after handling NAs: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Save Cleaned Data ---\n",
    "df.to_json(cleaned_file, orient=\"records\", lines=True, force_ascii=False)\n",
    "print(f\"Cleaned data saved to '{cleaned_file}'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
