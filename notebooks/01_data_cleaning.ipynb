{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Cleaning \n",
    "This notebook cleans the review data by putting it to lowercase, removing special characters and numbers, removing duplicates and incomplete reviews. The file is then saved to data/intermediate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# --- Project Directory Setup ---\n",
    "# Get the parent directory (project root)\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "from src1 import load_json_lines, save_json_lines, clean_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- File Paths Setup ---\n",
    "# Base directory (go 2 levels up from /src1/)\n",
    "base_dir = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "\n",
    "# Define input/output directories using relative paths\n",
    "input_dir = os.path.join(base_dir, \"data\", \"raw\")\n",
    "output_dir = os.path.join(base_dir, \"data\", \"intermediate\")\n",
    "\n",
    "input_filename = \"reviews_2021-01.json\"\n",
    "input_file = os.path.join(input_dir, input_filename)\n",
    "\n",
    "cleaned_file = os.path.join(output_dir, f\"cleaned_{input_filename}\")\n",
    "na_file = os.path.join(output_dir, \"NAs.json\")\n",
    "duplicates_file = os.path.join(output_dir, \"Duplicates.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data shape: (45490, 9)\n",
      "Columns: ['review_id', 'user_id', 'business_id', 'stars', 'useful', 'funny', 'cool', 'text', 'date']\n",
      "Missing values per column:\n",
      "review_id      0\n",
      "user_id        0\n",
      "business_id    0\n",
      "stars          0\n",
      "useful         0\n",
      "funny          0\n",
      "cool           0\n",
      "text           0\n",
      "date           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# --- Check if input file exists ---\n",
    "if not os.path.exists(input_file):\n",
    "    raise FileNotFoundError(f\"Error: File '{input_file}' not found.\")\n",
    "\n",
    "# --- Load Data ---\n",
    "reviews = load_json_lines(input_file)\n",
    "df = pd.DataFrame(reviews)\n",
    "\n",
    "# --- DataFrame creation ---\n",
    "df = pd.DataFrame(reviews)\n",
    "\n",
    "# --- Initial Checks ---\n",
    "print(f\"Initial data shape: {df.shape}\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")\n",
    "print(f\"Missing values per column:\\n{df.isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Text Cleaning ---\n",
    "if 'text' in df.columns:\n",
    "    df['text'] = df['text'].apply(clean_text)  # Clean the text field\n",
    "    df['text'] = df['text'].str.replace(r'\\s+', ' ', regex=True).str.strip()  # Normalize whitespace\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Remove Duplicates ---\n",
    "duplicates = df[df.duplicated(subset=['review_id'], keep=False)]\n",
    "if not duplicates.empty:\n",
    "    print(f\"Found {duplicates.shape[0]} duplicate reviews. Saving to '{duplicates_file}'.\")\n",
    "    duplicates.to_json(duplicates_file, orient=\"records\", lines=True, force_ascii=False)\n",
    "    \n",
    "df = df.drop_duplicates(subset=['review_id'], keep=\"first\")  # Remove duplicate reviews\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape after handling NAs: (45490, 9)\n"
     ]
    }
   ],
   "source": [
    "# --- Remove Empty Reviews ---\n",
    "df = df[df['text'].str.len() > 0]  # Remove reviews with empty text\n",
    "\n",
    "# --- Handle Missing Values ---\n",
    "nas = df[df.isnull().any(axis=1)]\n",
    "if not nas.empty:\n",
    "    print(f\"Found {nas.shape[0]} rows with missing values. Saving them to '{na_file}'.\")\n",
    "    nas.to_json(na_file, orient=\"records\", lines=True, force_ascii=False)\n",
    "\n",
    "df = df.dropna()  # Drop rows with any missing values\n",
    "print(f\"Data shape after handling NAs: {df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data saved to 'd:\\eigene Dateien\\Documents\\GitHub\\techlabs-data-science-yelp\\data\\intermediate\\cleaned_reviews_2021-01.json'\n"
     ]
    }
   ],
   "source": [
    "# --- Save Cleaned Data ---\n",
    "df.to_json(cleaned_file, orient=\"records\", lines=True, force_ascii=False)\n",
    "print(f\"Cleaned data saved to '{cleaned_file}'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
